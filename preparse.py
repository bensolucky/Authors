#######################################################################
# Sort paperauthors
import pandas as pd
import sys
from sets import Set
#######################################################################
#### Get the subset of authors that are found in paperauthors
# I do a few things to cut down the size of PaperAuthors because I'm 
# primarily working on a wimpy laptop
PaperAuthor = pd.read_csv("PaperAuthor.csv")
PaperAuthor = PaperAuthor.drop(['Name','Affiliation'], axis=1)
PaperAuthor.to_csv("PaperAuthor2.csv")
# Now get only the authors that are in paperauthors
PaperAuthor = pd.read_csv("PaperAuthor2.csv", index_col=0)
fin = open('Author.csv', 'r') 
fout = open('Author2.csv', 'w') 
print >>fout, "Id,Name,Affiliation"
fin.readline()
authors = Set(PaperAuthor['AuthorId'].values)
for line in fin:
    items = line.split(",")
    if int(items[0]) in authors:
        print >>fout, line,
fin.close()
fout.close()
########################################################################
#### AuthorsGroups - the author_groups.csv file is generated by
#### author_groups.py.  It finds repeated papers duplicates and collects
#### all the authors for these papers into an "author group".
authors = pd.read_csv("Author2.csv", index_col=0)
agroups = pd.read_csv("author_groups.csv")
agrps = authors.drop(['Name', 'Affiliation'], axis=1)
agrps['agrps'] = None
# For each author, find the author groups he/she is a member of
for aid in sorted(set(agroups['authorid'].values)):
    agrps['agrps'][aid] = agroups['authorgroup'][agroups['authorid']==aid].values
agrps = agrps[:][pd.notnull(agrps['agrps'])]
# Print out the dataframe, keyed on authorID and containing lists of 
# author groups
agrps.to_csv("Author8a6.tsv", sep="\t")
